[general]
openapi_key =
base_path = /Conversational_GPT
audio_path = data/Audio
document_output = data/Processed_data/audio_data.json


[vector_store]
vector_store_api = faiss
embedding = openai
local_vectorstore_dir = data/Processed_data/
vector_embedding_index = faiss_damac_audio_data

[audio]
whisper_model = small
translate = en
device = cuda

[APP]
streamlit_path = <path to environment>/envs/pylangchain/bin/streamlit


